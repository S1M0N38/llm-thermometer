services:
  language-model:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    volumes:
      - "${HF_HOME}:/root/.cache/huggingface"
    ports:
      - "41408:8000"
    environment:
      - "HF_HOME=/root/.cache/huggingface"
    command: >
      --model unsloth/Mistral-Small-24B-Instruct-2501-bnb-4bit
      --quantization bitsandbytes
      --load-format bitsandbytes
      --max-model-len 4096
      --max-seq-len-to-capture 4096
      --gpu-memory-utilization 0.7
      --seed 42
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  embedding-model:
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    runtime: nvidia
    volumes:
      - "${HF_HOME}:/root/.cache/huggingface"
    ports:
      - "41409:80"
    environment:
      - "HF_HOME=/root/.cache/huggingface"
    command: >
      --model-id jinaai/jina-embeddings-v2-base-en
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  language-model:
  embedding-model:
